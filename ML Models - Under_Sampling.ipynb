{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4ByBijTDp0y"
      },
      "source": [
        "We are use the popular Flights Dataset to analyze and predict flight delays in airports based on past flight records.\n",
        "For this dataset, we will only look at the flights in 2014 ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO12e4VvD3PA",
        "outputId": "f7b780ea-3adf-4083-dbb4-ac620332bca4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzf5EpldDp00"
      },
      "source": [
        "# Import findspark and findspark.init() to make pyspark importable as a regular library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYxGI2K6Dp02"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "conf = SparkConf().setAppName('appName').setMaster('local')\n",
        "sc = SparkContext(conf=conf)\n",
        "spark = SparkSession(sc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XNpA1WRDp02"
      },
      "source": [
        "#importing some packages we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3Z3KRK7Dp02"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import Row\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.mllib.linalg import Vectors\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.param import Param, Params\n",
        "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from pyspark.mllib.stat import Statistics\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
        "from pyspark.mllib.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from IPython.display import display\n",
        "from ipywidgets import interact\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path\n",
        "import pyarrow as pa\n",
        "from pyarrow import csv\n",
        "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be4HTj_QDp03"
      },
      "source": [
        "Removing headers of the dataset and renaming it so that further it will be easier for us analyse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1hfcpjXDp03"
      },
      "outputs": [],
      "source": [
        "textFile = sc.textFile('cleaned_dataset.csv')\n",
        "textFileRDD = textFile.map(lambda x: x.split(','))\n",
        "header = textFileRDD.first()\n",
        "textRDD = textFileRDD.filter(lambda r: r != header)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx9azhJgDp03"
      },
      "source": [
        "# Creating the Dataframe from RDD (Resilient Distributed Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juubd2gBDp04",
        "outputId": "4e5b23e8-78bf-4715-ef81-ad31d7392896"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def parse(r):\n",
        "    try:\n",
        "        x=Row(Year=int(r[0]),\\\n",
        "          Month=int(r[1]),\\\n",
        "          DayofMonth=int(r[2]),\\\n",
        "          DayOfWeek=int(r[3]),\\\n",
        "          DepTime=int(float(r[8])), \\\n",
        "          CRSDepTime=int(r[7]),\\\n",
        "          ArrTime=int(float(r[11])),\\\n",
        "          CRSArrTime=int(r[10]), \\\n",
        "          UniqueCarrier=r[4],\\\n",
        "          DepDelay=int(float(r[9])),\\\n",
        "          Origin=r[5],\\\n",
        "          Dest=r[6], \\\n",
        "          Distance=int(float(r[12])),\\\n",
        "          CarrierDelay=int(float(r[13])),\\\n",
        "          WeatherDelay=int(float(r[14])),\\\n",
        "          NASDelay= int(float(r[15])),\\\n",
        "          SecurityDelay=int(float(r[16])),\\\n",
        "          LateAircraftDelay=int(float(r[17])))\n",
        "    except:\n",
        "        x=None\n",
        "    return x\n",
        "\n",
        "rowRDD = textRDD.map(lambda r: parse(r)).filter(lambda r:r != None)\n",
        "sqlContext = SQLContext(sc)\n",
        "airline_df = sqlContext.createDataFrame(rowRDD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkcbDvmSDp04"
      },
      "source": [
        "DepDelayed is a new column added to dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A6oE771birC"
      },
      "source": [
        "Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVpbGgBADp04"
      },
      "source": [
        "True for delay > 15 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npQBLnZMDp04"
      },
      "source": [
        "False for delay <=15 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08xKJYDADp05"
      },
      "outputs": [],
      "source": [
        "airline_df = airline_df.withColumn('DepDelayed', when(airline_df['DepDelay'] > 15, 1).otherwise(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLlnRUr6Dp05",
        "outputId": "74ec2a6b-a8b5-4f08-a5a2-eb84e7e028dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
            "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# define hour function to obtain hour of day\n",
        "def hour_ex(x):\n",
        "    h = int(str(int(x)).zfill(4)[:2])\n",
        "    return h\n",
        "\n",
        "# register as a UDF\n",
        "sqlContext.udf.register(\"hour_ex_py\",hour_ex, IntegerType())\n",
        "f_udf = udf(hour_ex, IntegerType())\n",
        "\n",
        "#CRSDepTime: scheduled departure time (local, hhmm)\n",
        "airline_df = airline_df.withColumn('hour', f_udf(airline_df.CRSDepTime))\n",
        "airline_df.registerTempTable(\"airlineDF\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-2SlBaEDp05",
        "outputId": "6b4cea86-bc7f-4a93-eee2-97988643de81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(Year=2014, Month=1, DayofMonth=3, DayOfWeek=5, DepTime=1513, CRSDepTime=1510, ArrTime=1621, CRSArrTime=1620, UniqueCarrier='AA', DepDelay=3, Origin='DFW', Dest='SAT', Distance=247, CarrierDelay=0, WeatherDelay=0, NASDelay=0, SecurityDelay=0, LateAircraftDelay=0, DepDelayed=0, hour=15),\n",
              " Row(Year=2014, Month=1, DayofMonth=4, DayOfWeek=6, DepTime=1522, CRSDepTime=1510, ArrTime=1618, CRSArrTime=1620, UniqueCarrier='AA', DepDelay=12, Origin='DFW', Dest='SAT', Distance=247, CarrierDelay=0, WeatherDelay=0, NASDelay=0, SecurityDelay=0, LateAircraftDelay=0, DepDelayed=0, hour=15),\n",
              " Row(Year=2014, Month=1, DayofMonth=5, DayOfWeek=7, DepTime=1522, CRSDepTime=1510, ArrTime=1624, CRSArrTime=1620, UniqueCarrier='AA', DepDelay=12, Origin='DFW', Dest='SAT', Distance=247, CarrierDelay=0, WeatherDelay=0, NASDelay=0, SecurityDelay=0, LateAircraftDelay=0, DepDelayed=0, hour=15),\n",
              " Row(Year=2014, Month=1, DayofMonth=6, DayOfWeek=1, DepTime=1612, CRSDepTime=1510, ArrTime=1710, CRSArrTime=1620, UniqueCarrier='AA', DepDelay=62, Origin='DFW', Dest='SAT', Distance=247, CarrierDelay=10, WeatherDelay=0, NASDelay=0, SecurityDelay=0, LateAircraftDelay=40, DepDelayed=1, hour=15),\n",
              " Row(Year=2014, Month=1, DayofMonth=7, DayOfWeek=2, DepTime=1505, CRSDepTime=1510, ArrTime=1615, CRSArrTime=1620, UniqueCarrier='AA', DepDelay=-5, Origin='DFW', Dest='SAT', Distance=247, CarrierDelay=0, WeatherDelay=0, NASDelay=0, SecurityDelay=0, LateAircraftDelay=0, DepDelayed=0, hour=15)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "airline_df.head(n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8ylt7R_Wrd3"
      },
      "source": [
        "Feature Selection:\n",
        "\n",
        "1.   Decide which columns will be features (X) and the target (y).\n",
        "2.   Drop unnecessary or redundant columns that won't contribute to the prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHcUsBmrWqS6"
      },
      "outputs": [],
      "source": [
        "# Drop columns you donâ€™t need for modeling\n",
        "columns_to_drop = ['Year', 'DepDelay', 'ArrDelay', 'DepTime', 'ArrTime', 'CRSArrTime']\n",
        "airline_df = airline_df.drop(*columns_to_drop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2kL9ThAXf4L"
      },
      "source": [
        "One-Hot Encoding\n",
        "\n",
        "*   Convert categorical columns (UniqueCarrier, Origin, Dest) into numerical formats using one-hot encoding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo97A-23XvY8"
      },
      "source": [
        "Assemble Features\n",
        "\n",
        "*   Combine all features into a single vector for model input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNmMKibxX6i3"
      },
      "source": [
        "Train-Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsDqq-rloDPx"
      },
      "source": [
        "Check for Class Imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z1dwbsGolfC"
      },
      "source": [
        "**Based on the class distribution we can see:**\n",
        "\n",
        "1.   1143834 delayed flights (1) (about 20% of the dataset)\n",
        "2.   4532505 on-time flights (0) (about 80% of the dataset)\n",
        "\n",
        "\n",
        "\n",
        "Our dataset is imbalanced, with a much higher proportion of on-time flights compared to delayed flights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvI7QOKapGR9"
      },
      "source": [
        "**What Does This Mean for Your Model?**\n",
        "\n",
        "Accuracy: If your model predicts no delay (class 0) for almost all flights, it could still achieve a high accuracy (~80%) because the majority class (on-time) is so dominant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2CJgoqkpZie"
      },
      "source": [
        "Under Sampling Majority Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHkMdRtfgLW5",
        "outputId": "d6ca61e6-8090-4c54-f456-80b4d7a3e41d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-------+\n",
            "|DepDelayed|  count|\n",
            "+----------+-------+\n",
            "|         1|1147992|\n",
            "|         0|4542191|\n",
            "+----------+-------+\n",
            "\n",
            "+----------+-------+\n",
            "|DepDelayed|  count|\n",
            "+----------+-------+\n",
            "|         1|1147992|\n",
            "|         0|1146245|\n",
            "+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Checking class distribution based on the 'DepDelayed' column\n",
        "airline_df.groupBy(\"DepDelayed\").count().show()\n",
        "\n",
        "# Undersample the majority class (0 - on-time flights)\n",
        "fraction_delayed = 1.0  # Keep all delayed flights (1s)\n",
        "fraction_on_time = 1143834 / 4532505  # Undersample on-time flights to match the delayed ones\n",
        "\n",
        "# Undersampling the majority class\n",
        "balanced_airline_df = airline_df.sampleBy(\"DepDelayed\", fractions={0: fraction_on_time, 1: fraction_delayed}, seed=42)\n",
        "\n",
        "# Verifying new class distribution\n",
        "balanced_airline_df.groupBy(\"DepDelayed\").count().show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2shO99p7E_zf"
      },
      "outputs": [],
      "source": [
        "# Index and encode categorical variables\n",
        "indexer_carrier = StringIndexer(inputCol=\"UniqueCarrier\", outputCol=\"UniqueCarrierIndex\")\n",
        "encoder_carrier = OneHotEncoder(inputCol=\"UniqueCarrierIndex\", outputCol=\"UniqueCarrierVec\")\n",
        "\n",
        "indexer_origin = StringIndexer(inputCol=\"Origin\", outputCol=\"OriginIndex\")\n",
        "encoder_origin = OneHotEncoder(inputCol=\"OriginIndex\", outputCol=\"OriginVec\")\n",
        "\n",
        "indexer_dest = StringIndexer(inputCol=\"Dest\", outputCol=\"DestIndex\")\n",
        "encoder_dest = OneHotEncoder(inputCol=\"DestIndex\", outputCol=\"DestVec\")\n",
        "\n",
        "# Create a pipeline to ensure transformations are sequential\n",
        "pipeline = Pipeline(stages=[\n",
        "    indexer_carrier, encoder_carrier,\n",
        "    indexer_origin, encoder_origin,\n",
        "    indexer_dest, encoder_dest\n",
        "])\n",
        "\n",
        "# Fit and transform the pipeline on the balanced dataset\n",
        "model = pipeline.fit(balanced_airline_df)\n",
        "balanced_airline_df = model.transform(balanced_airline_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyc4nX-unjna"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"hour\", \"Distance\", \"UniqueCarrierVec\", \"OriginVec\", \"DestVec\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "balanced_airline_df = assembler.transform(balanced_airline_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBykqDUDn4Qz",
        "outputId": "57b82a93-6cac-4505-d1c0-0b30c8c59d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime', 'UniqueCarrier', 'Origin', 'Dest', 'Distance', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'DepDelayed', 'hour', 'UniqueCarrierIndex', 'UniqueCarrierVec', 'OriginIndex', 'OriginVec', 'DestIndex', 'DestVec', 'features']\n"
          ]
        }
      ],
      "source": [
        "print(balanced_airline_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anNBHALepAZK"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = balanced_airline_df.randomSplit([0.8, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbK1bbEipPxK"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"DepDelayed\",\n",
        "    numTrees=50,\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LOZoFPxpbko"
      },
      "outputs": [],
      "source": [
        "model = rf.fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pahEhGMyephy"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(predictions):\n",
        "   \n",
        "    metrics = predictions.groupBy(\"DepDelayed\", \"prediction\").count().toPandas()\n",
        "    TP = metrics[(metrics[\"DepDelayed\"] == 1) & (metrics[\"prediction\"] == 1)][\"count\"].sum()\n",
        "    FP = metrics[(metrics[\"DepDelayed\"] == 0) & (metrics[\"prediction\"] == 1)][\"count\"].sum()\n",
        "    FN = metrics[(metrics[\"DepDelayed\"] == 1) & (metrics[\"prediction\"] == 0)][\"count\"].sum()\n",
        "    TN = metrics[(metrics[\"DepDelayed\"] == 0) & (metrics[\"prediction\"] == 0)][\"count\"].sum()\n",
        "\n",
        "   \n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return precision, recall, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iksRYd4pd-g",
        "outputId": "e6495d17-df3a-45f2-d24e-1ca4b27c2278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC-ROC: 0.6730430321524823\n",
            "Precision: 0.6109722321124058, Recall: 0.7104431689916805, F1-Score: 0.6569638107519948\n",
            "+----------+----------+------+\n",
            "|DepDelayed|prediction| count|\n",
            "+----------+----------+------+\n",
            "|         1|       0.0| 66442|\n",
            "|         0|       0.0|125157|\n",
            "|         1|       1.0|163019|\n",
            "|         0|       1.0|103800|\n",
            "+----------+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Make predictions\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate AUC-ROC\n",
        "evaluator = BinaryClassificationEvaluator(\n",
        "    labelCol=\"DepDelayed\",\n",
        "    rawPredictionCol=\"rawPrediction\",\n",
        "    metricName=\"areaUnderROC\"\n",
        ")\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f\"AUC-ROC: {auc}\")\n",
        "precision, recall, f1_score = calculate_metrics(predictions)\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1-Score: {f1_score}\")\n",
        "# Evaluate precision and recall\n",
        "predictions.groupBy(\"DepDelayed\", \"prediction\").count().show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHhOTGEOpbVO"
      },
      "source": [
        "The accuracy is approximately 62.87%.\n",
        "\n",
        "> Add blockquote\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fPrNr-9vB2n",
        "outputId": "fa70a96f-1f5a-41c0-eb46-e12d56c4def9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression AUC-ROC: 0.6858332470556392\n",
            "Precision: 0.634198924758563, Recall: 0.6508616784785957, F1-Score: 0.6424222727206289\n",
            "+----------+----------+------+\n",
            "|DepDelayed|prediction| count|\n",
            "+----------+----------+------+\n",
            "|         1|       0.0|400808|\n",
            "|         0|       0.0|715275|\n",
            "|         1|       1.0|747184|\n",
            "|         0|       1.0|430970|\n",
            "+----------+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr = LogisticRegression(labelCol=\"DepDelayed\", featuresCol=\"features\")\n",
        "lr_model = lr.fit(balanced_airline_df)\n",
        "lr_predictions = lr_model.transform(balanced_airline_df)\n",
        "\n",
        "# Evaluate\n",
        "lr_auc = evaluator.evaluate(lr_predictions)\n",
        "print(f\"Logistic Regression AUC-ROC: {lr_auc}\")\n",
        "precision, recall, f1_score = calculate_metrics(lr_predictions)\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1-Score: {f1_score}\")\n",
        "lr_predictions.groupBy(\"DepDelayed\", \"prediction\").count().show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRv_k2BTvEz3",
        "outputId": "f52005b1-8f64-4762-8e17-d9f465b16fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree AUC-ROC: 0.5332783605705813\n",
            "Precision: 0.6049811413420918, Recall: 0.6867295242475557, F1-Score: 0.6432685313207461\n",
            "+----------+----------+------+\n",
            "|DepDelayed|prediction| count|\n",
            "+----------+----------+------+\n",
            "|         1|       0.0|359632|\n",
            "|         0|       0.0|631490|\n",
            "|         1|       1.0|788360|\n",
            "|         0|       1.0|514755|\n",
            "+----------+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dt = DecisionTreeClassifier(labelCol=\"DepDelayed\", featuresCol=\"features\", maxDepth=5)\n",
        "dt_model = dt.fit(balanced_airline_df)\n",
        "dt_predictions = dt_model.transform(balanced_airline_df)\n",
        "\n",
        "# Evaluate\n",
        "dt_auc = evaluator.evaluate(dt_predictions)\n",
        "print(f\"Decision Tree AUC-ROC: {dt_auc}\")\n",
        "precision, recall, f1_score = calculate_metrics(dt_predictions)\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1-Score: {f1_score}\")\n",
        "dt_predictions.groupBy(\"DepDelayed\", \"prediction\").count().show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqhTO7iGcBR-",
        "outputId": "b34eb95b-cd31-4423-c651-727dcd022713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting model training...\n",
            "Model training completed.\n",
            "Best Model Parameters: regParam=0.01, elasticNetParam=0.0, maxIter=100\n",
            "Test AUC-ROC: 0.6539\n"
          ]
        }
      ],
      "source": [
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Logistic Regression with Hyperparameter Tuning\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "data = spark.read.csv(\"cleaned_dataset.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Create a binary label column (1: Delayed > 15 mins, 0: Not Delayed)\n",
        "data = data.withColumn(\"DEP_DELAY\", when(col(\"DEP_DELAY\") > 15, 1).otherwise(0))\n",
        "\n",
        "\n",
        "carrier_indexer = StringIndexer(inputCol=\"OP_UNIQUE_CARRIER\", outputCol=\"CarrierIndex\", handleInvalid=\"skip\")\n",
        "origin_indexer = StringIndexer(inputCol=\"ORIGIN\", outputCol=\"OriginIndex\", handleInvalid=\"skip\")\n",
        "dest_indexer = StringIndexer(inputCol=\"DEST\", outputCol=\"DestIndex\", handleInvalid=\"skip\")\n",
        "\n",
        "# Assemble feature vector\n",
        "feature_columns = ['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'CRS_DEP_TIME',\n",
        "                   'CarrierIndex', 'OriginIndex', 'DestIndex', 'DISTANCE']\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=[carrier_indexer, origin_indexer, dest_indexer, assembler])\n",
        "\n",
        "data = pipeline.fit(data).transform(data)\n",
        "\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Adding class weights (to handle class imbalance)\n",
        "train_data = train_data.withColumn(\n",
        "    \"classWeight\",\n",
        "    when(col(\"DEP_DELAY\") == 1, 1.5).otherwise(1)\n",
        ")\n",
        "\n",
        "\n",
        "lr = LogisticRegression(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"DEP_DELAY\",  \n",
        "    weightCol=\"classWeight\", \n",
        "    regParam=0.1,\n",
        "    elasticNetParam=0.5,\n",
        "    maxIter=50\n",
        ")\n",
        "\n",
        "# Define Hyperparameter Grid\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(lr.regParam, [0.01, 0.1, 0.5]) \\\n",
        "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
        "    .addGrid(lr.maxIter, [10, 50, 100]) \\\n",
        "    .build()\n",
        "\n",
        "# Define Cross-Validator\n",
        "evaluator = BinaryClassificationEvaluator(\n",
        "    labelCol=\"DEP_DELAY\",\n",
        "    metricName=\"areaUnderROC\"\n",
        ")\n",
        "crossval = CrossValidator(\n",
        "    estimator=lr,\n",
        "    estimatorParamMaps=paramGrid,\n",
        "    evaluator=evaluator,\n",
        "    numFolds=3\n",
        ")\n",
        "\n",
        "print(\"Starting model training...\")\n",
        "cv_model = crossval.fit(train_data)\n",
        "print(\"Model training completed.\")\n",
        "\n",
        "# Evaluate Best Model\n",
        "best_model = cv_model.bestModel\n",
        "print(f\"Best Model Parameters: regParam={best_model._java_obj.getRegParam()}, \"\n",
        "      f\"elasticNetParam={best_model._java_obj.getElasticNetParam()}, \"\n",
        "      f\"maxIter={best_model._java_obj.getMaxIter()}\")\n",
        "\n",
        "\n",
        "predictions = best_model.transform(test_data)\n",
        "\n",
        "# Evaluate Predictions\n",
        "auc_roc = evaluator.evaluate(predictions)\n",
        "print(f\"Test AUC-ROC: {auc_roc:.4f}\")\n",
        "\n",
        "\n",
        "best_model.write().overwrite().save(\"logistic_regression_best_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpdRH6E4m-ff"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
